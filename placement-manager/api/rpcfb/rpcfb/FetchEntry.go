// Code generated by the FlatBuffers compiler. DO NOT EDIT.

package rpcfb

import (
	flatbuffers "github.com/google/flatbuffers/go"
)

type FetchEntryT struct {
	Range *RangeT `json:"range"`
	FetchOffset int64 `json:"fetch_offset"`
	EndOffset int64 `json:"end_offset"`
	BatchMaxBytes int32 `json:"batch_max_bytes"`
}

func (t *FetchEntryT) Pack(builder *flatbuffers.Builder) flatbuffers.UOffsetT {
	if t == nil { return 0 }
	range_Offset := t.Range.Pack(builder)
	FetchEntryStart(builder)
	FetchEntryAddRange(builder, range_Offset)
	FetchEntryAddFetchOffset(builder, t.FetchOffset)
	FetchEntryAddEndOffset(builder, t.EndOffset)
	FetchEntryAddBatchMaxBytes(builder, t.BatchMaxBytes)
	return FetchEntryEnd(builder)
}

func (rcv *FetchEntry) UnPackTo(t *FetchEntryT) {
	t.Range = rcv.Range(nil).UnPack()
	t.FetchOffset = rcv.FetchOffset()
	t.EndOffset = rcv.EndOffset()
	t.BatchMaxBytes = rcv.BatchMaxBytes()
}

func (rcv *FetchEntry) UnPack() *FetchEntryT {
	if rcv == nil { return nil }
	t := &FetchEntryT{}
	rcv.UnPackTo(t)
	return t
}

type FetchEntry struct {
	_tab flatbuffers.Table
}

func GetRootAsFetchEntry(buf []byte, offset flatbuffers.UOffsetT) *FetchEntry {
	n := flatbuffers.GetUOffsetT(buf[offset:])
	x := &FetchEntry{}
	x.Init(buf, n+offset)
	return x
}

func GetSizePrefixedRootAsFetchEntry(buf []byte, offset flatbuffers.UOffsetT) *FetchEntry {
	n := flatbuffers.GetUOffsetT(buf[offset+flatbuffers.SizeUint32:])
	x := &FetchEntry{}
	x.Init(buf, n+offset+flatbuffers.SizeUint32)
	return x
}

func (rcv *FetchEntry) Init(buf []byte, i flatbuffers.UOffsetT) {
	rcv._tab.Bytes = buf
	rcv._tab.Pos = i
}

func (rcv *FetchEntry) Table() flatbuffers.Table {
	return rcv._tab
}

func (rcv *FetchEntry) Range(obj *Range) *Range {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(4))
	if o != 0 {
		x := rcv._tab.Indirect(o + rcv._tab.Pos)
		if obj == nil {
			obj = new(Range)
		}
		obj.Init(rcv._tab.Bytes, x)
		return obj
	}
	return nil
}

func (rcv *FetchEntry) FetchOffset() int64 {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(6))
	if o != 0 {
		return rcv._tab.GetInt64(o + rcv._tab.Pos)
	}
	return 0
}

func (rcv *FetchEntry) MutateFetchOffset(n int64) bool {
	return rcv._tab.MutateInt64Slot(6, n)
}

func (rcv *FetchEntry) EndOffset() int64 {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(8))
	if o != 0 {
		return rcv._tab.GetInt64(o + rcv._tab.Pos)
	}
	return 0
}

func (rcv *FetchEntry) MutateEndOffset(n int64) bool {
	return rcv._tab.MutateInt64Slot(8, n)
}

func (rcv *FetchEntry) BatchMaxBytes() int32 {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(10))
	if o != 0 {
		return rcv._tab.GetInt32(o + rcv._tab.Pos)
	}
	return 0
}

func (rcv *FetchEntry) MutateBatchMaxBytes(n int32) bool {
	return rcv._tab.MutateInt32Slot(10, n)
}

func FetchEntryStart(builder *flatbuffers.Builder) {
	builder.StartObject(4)
}
func FetchEntryAddRange(builder *flatbuffers.Builder, range_ flatbuffers.UOffsetT) {
	builder.PrependUOffsetTSlot(0, flatbuffers.UOffsetT(range_), 0)
}
func FetchEntryAddFetchOffset(builder *flatbuffers.Builder, fetchOffset int64) {
	builder.PrependInt64Slot(1, fetchOffset, 0)
}
func FetchEntryAddEndOffset(builder *flatbuffers.Builder, endOffset int64) {
	builder.PrependInt64Slot(2, endOffset, 0)
}
func FetchEntryAddBatchMaxBytes(builder *flatbuffers.Builder, batchMaxBytes int32) {
	builder.PrependInt32Slot(3, batchMaxBytes, 0)
}
func FetchEntryEnd(builder *flatbuffers.Builder) flatbuffers.UOffsetT {
	return builder.EndObject()
}
