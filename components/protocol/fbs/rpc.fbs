namespace header;

// Use HTTP status codes where possible: https://en.wikipedia.org/wiki/List_of_HTTP_status_codes
// 5xx is not used as we have two kinds of servers: placement manager and data node. Instead, use
// 15xx for placement manager errors and 25xx for data node errors.
enum ErrorCode : int16 {
    ERROR_CODE_UNSPECIFIED = 0,
    
    // Error when encoding protocol structs into buffers.
    ENCODE = 1,

    // Error when decoding buffers into protocol structs
    DECODE = 2,

    // 12xx means success or partial success.
    OK = 1200,
    // Requested offset = next_offset. Note that this code only applies to open ranges.
    NO_NEW_RECORD = 1204,

    // 14xx for client errors
    BAD_REQUEST = 1400,
    UNAUTHORIZED = 1401,
    PAYMENT_REQUIRED = 1402,
    FORBIDDEN = 1403,
    NOT_FOUND = 1404,
    METHOD_NOT_ALLOWED = 1405,
    PRECONDITION_FAILED = 1412,
    PAYLOAD_TOO_LARGE = 1413,
    TOO_MANY_REQUESTS = 1429,
    HEADER_FIELDS_TOO_LARGE = 1431,
    UNAVAILABLE_FOR_LEGAL_REASONS = 1451,
    // Invalid request for a sealed range, such as appending.
    RANGE_ALREADY_SEALED = 1460,
    // For an open range, the requested offset > next_offset. 
    OFFSET_OVERFLOW = 1461,
    // Requested range not found.
    RANGE_NOT_FOUND = 1462,
    // For a sealed range, the requested offset is out of range bounds. For an open range, the requested offset < start_offset.
    OFFSET_OUT_OF_RANGE_BOUNDS = 1463,
    // Try to create a new range when the last range in the stream is not sealed.
    CREATE_RANGE_BEFORE_SEAL = 1470,
    // Try to seal a range with an epoch which is smaller than the current range's epoch.
    // or
    // Try to create a new range with an epoch that is smaller than the previous range's epoch.
    EXPIRED_RANGE_EPOCH = 1471,

    // Server understands the intended operation but it does not support that.
    UNSUPPORTED_OPERATION = 1498,

    // The operation is unknown.
    UNKNOWN_OPERATION = 1499,

    // 15xx is reserved for placement manager errors
    // In case placement manager encounters an internal error, normally, this implies 
    // that a design or implementation bug is triggered and should be fixed.
    PM_INTERNAL_SERVER_ERROR = 1500,

    // Feature not implemented yet.
    PM_NOT_IMPLEMENTED = 1501,

    // When creating a new stream or sealing a mutable range, placement managers need to create
    // a new replica-set of mutable range, which requires at least replica number of survival 
    // data nodes. If this requirement is not met, use this error code to signal the client.
    PM_NO_AVAILABLE_DN = 1502,

    // Placement manager nodes are running RAFT consensus algorithm, write operations should go to
    // leader nodes. Otherwise, use this code to signal the client to redirect future requests.
    PM_NOT_LEADER = 1503,

    // 25xx is reserved for data node errors
    DN_INTERNAL_SERVER_ERROR = 2500,
    DN_NOT_IMPLEMENTED = 2501,
}

// The Status type defines a logical error model.
// Each `Status` message contains three pieces of data: error code, error message, and error detail.
table Status {
    // The top-level error code, or 0 if there was no error.
    code: ErrorCode (id: 0);
    
    // The error message, or omitted if there was no error.
    message: string (id: 1);

    // Additional information about the error, if any.
    // Its format depends on the specific `ErrorCode`.
    detail: [ubyte] (id: 2);
}

// The Placement Manager information.
// It will be set in `Status.detail` if the `Status.code` is `PM_NOT_LEADER`.
table PlacementManagerCluster {
    nodes: [PlacementManagerNode] (id: 0, required);
}

// A node in the Placement Manager.
table PlacementManagerNode {
    // The name of the PM node.
    name: string (id: 0, required);

    // The advertise address of the PM node, for client traffic from outside.
    // The schema of the address is `host:port`, while host supports both domain name and IPv4/IPv6 address.
    advertise_addr: string (id: 1, required);

    is_leader: bool (id: 2);
}

// The system error is used to return the error code and error message if the system error flag of sbp is set.
table SystemError {
    status: Status (id: 0, required);
}

enum ClientRole : byte {
    CLIENT_ROLE_UNSPECIFIED = 0,
    CLIENT_ROLE_PM = 1,
    CLIENT_ROLE_DATA_NODE = 2,
    CLIENT_ROLE_CUSTOMER = 3,
}

// The heartbeat is used to keep the connection alive.
table HeartbeatRequest {
    // The unique id of the client.
    client_id: string (id: 0);

    // The role of the client. The client role is used to determine the type of the client.
    client_role: ClientRole (id: 1);
    
    // Optional, the node information of the data node. Empty if the client is an SDK client.
    data_node: DataNode (id: 2);
}

table HeartbeatResponse {
    client_id: string (id: 0);
    
    client_role: ClientRole (id: 1);
    
    data_node: DataNode (id: 2);
    
    status: Status (id: 3, required);
}

// Request placement manager to allocate a unique ID. 
table IdAllocationRequest {
    timeout_ms: int32 (id: 0);
    
    host: string (id: 1, required);
}

// Unique ID allocation response
table IdAllocationResponse {
    status: Status (id: 0, required);

    // Allocated node-id
    id: int32 (id: 1);
}

// The append request is used to append records to the data node.
table AppendRequest {
    // The timeout to await a response in milliseconds.
    timeout_ms: int32 (id: 0);

    // Other fields are serialized in the payload.
    // Layout of the request payload
    // +-------------------+-------------------+-------------------+-------------------+
    // |  AppendEntry 1    |  AppendEntry 2    |  AppendEntry 3    |        ...        |
    // +-------------------+-------------------+-------------------+-------------------+
    //
    // Layout of AppendEntry
    // +-------------------+-------------------+-------------------+------------------------------------------+
    // |  Magic Code(1B)   |  Meta Len(4B)     |       Meta        |  Payload Len(4B) | Record Batch Payload  |
    // +-------------------+-------------------+-------------------+------------------------------------------+
}

table AppendResponse {
    // Status for overall RPC.
    status: Status (id: 0, required);

    // A batch of append responses.
    entries: [AppendResultEntry] (id: 1);

    // The time in milliseconds to throttle the client, due to a quota violation or the server is too busy.
    throttle_time_ms: int32 (id: 2);
}

table AppendResultEntry {
    // Status for the AppendEntry
    status: Status (id: 0, required);

    // The timestamp returned by the data node server after appending the records.
    timestamp_ms: int64 (id: 1);
}

// The fetch request is used to fetch records from the data node.
// This frame supports fetching data from multiple streams in one frame,
// and the response could be split into multiple frames then returned in a streaming way.
table FetchRequest {
    // The maximum time in milliseconds to wait for the response.
    max_wait_ms: int32 (id: 0);

    // The minimum bytes to accumulate before returning a response.
    min_bytes: int32 (id: 1);

    // A batch of fetch requests to fetch data from different streams.
    entries: [FetchEntry] (id: 2);
}

table FetchEntry {
    // The stream range to fetch.
    range: Range (id: 0, required);
    
    // The offset to fetch from.
    fetch_offset: int64 (id: 1);

    // The exclusive end offset to fetch.
    end_offset: int64 (id: 2);
    
    // The maximum number of bytes to fetch.
    batch_max_bytes: int32 (id: 3);
}

table FetchResponse {
    status: Status (id: 0, required);

    // A batch of `FetchResultEntry`.
    entries: [FetchResultEntry] (id: 1);

    // The time in milliseconds to throttle the client, due to a quota violation or the server is too busy.
    throttle_time_ms: int32 (id: 2);
}

table FetchResultEntry {
    status: Status (id: 0, required);

    // The id of the stream
    stream_id: int64 = -1 (id: 1);

    // The quantity of record batches to be decoded from the payload for current fetch result.
    //
    // Note: Record batches MUST be decoded sequentially. 
    // This field defines the quantity of record batches that are belonging to the current FetchResult.
    batch_count: int32 (id: 2);
}

// Used to fetch the ranges from a specific data node or a specific stream list.
// Regard this table as a union type.
// Alway set one of the fields.
table ListRangeCriteria {
    // If non-negative, placement managers are expected to filter ranges assigned to the specified node.
    node_id: int32 = -1 (id: 0);

    // The stream id to list the ranges.
    stream_id: int64 = -1 (id: 1);
}

table DataNode {
    // The node id of the data node.
    node_id: int32 = -1 (id: 0);

    // The advertise address of the data node, for client traffic from outside.
    // The schema of the address is `host:port`, while host supports both domain name and IPv4/IPv6 address.
    advertise_addr: string (id: 1, required);
}

// The list streams request is used to list the ranges of a batch of streams.
// Or it could list the ranges of all the streams in a specific data node.
table ListRangeRequest {
    timeout_ms: int32 (id: 0);

    // The range criteria could be a data node or a list of streams.
    criteria: ListRangeCriteria (id: 1, required);
}

table ListRangeResponse {
    status: Status (id: 0, required);

    // The time in milliseconds to throttle the client, due to a quota violation or the server is too busy.
    throttle_time_ms: int32 (id: 1);

    // The list of ranges.
    ranges: [Range] (id: 2, required);
}

table Range {
    // The id of the stream
    stream_id: int64 = -1 (id: 0);

    // At the epoch when the range is created. Valid values are non-negative.
    epoch: int64 = -1 (id: 1);

    // The index of the range in the stream.
    index: int32 = -1 (id: 2);

    // The start offset of the range. Offset is 0-based index and follows left-boundary-inclusive and right-boundary-exclusive.
    start: int64 = -1 (id: 3);

    // The end offset of the range.
    // -1 if the range is mutable. If the range is sealed, end_offset would be non-negative and `end_offset` is exclusive.
    //
    // For example, range `[0, -1)` means that it is still mutable and clients may append additional records to it;
    // range `[0, 100)` means it is already sealed and read-only, records indexed 0 to 99 can be retrieved from this range;
    // we may have empty, droppable sealed ranges with the form `[N, N)` and placement manager would delete them without hesitation,
    // as a result, clients should NOT cache these empty ones.
    end: int64 = -1 (id: 4);

    // The collection of data-node that host this range.
    nodes: [DataNode] (id: 5);

    // The range replica expected count.
    replica_count: int8 = -1 (id: 6);

    // The range replica ack count, only success ack > ack, then the write is success.
    ack_count: int8 = -1 (id: 7);
}

table CreateRangeRequest {
    timeout_ms: int32 (id: 0);

    range: Range (id: 1, required);
}

table CreateRangeResponse {
    status: Status (id: 0, required);

    range: Range (id: 1);

    // The time in milliseconds to throttle the client, due to a quota violation or the server is too busy.
    throttle_time_ms: int32 (id: 2);
}

// Seal target kinds.
//
// Replication layer SDK performs two kinds of seals: seal-data-node and seal-placement-manager.
// The former one renders ranges on data-node immutable and blocks further writes. In the scenario of chasing
// write, replication SDK acknowledges application if MinCopy out of MaxCopy replicas are successfully written in data nodes
// within the configured amount of tolerance, where 2 * MinCopy > MaxCopy. Otherwise, replication SDK initiates seal actions
// of the range towards data-nodes. Data nodes, on receipt of replication SDK seal, immediately changes range as immutable and
// returns currently confirmed offset and fails all inflight and future writes to current range.
//
// After receiving at least MinCopy of data-node seal responses, replication layer SDK is safe to seal the range in placement manager
// and potentially create a new range, replicas of which reside on a different set of data nodes. This achieves fast fault toleration
// as well as overall low write latency.
enum SealKind : byte {
    UNSPECIFIED = 0,
    DATA_NODE = 1,
    PLACEMENT_MANAGER = 2,
}

table SealRangeRequest {
    timeout_ms: int32 (id: 0);

    kind: SealKind    (id: 1);

    // If the seal-type is placement-manager, end is the final upper boundary of the range being sealed.     
    range: Range      (id: 2, required);
}

table SealRangeResponse {
    status: Status (id: 0, required);

    // Both the PM and the data node will handle the seal ranges request.
    range: Range (id: 1);

    // The time in milliseconds to throttle the client, due to a quota violation or the server is too busy.
    throttle_time_ms: int32 (id: 2);
}

table Stream {
    // The id of the stream
    // Omitted if the stream is not created.
    stream_id: int64 = -1 (id: 0);

    // The number of replica of the stream.
    replica: int8 (id: 1);

    // The number of ack of the stream.
    ack_count: int8 (id: 2);
    
    // The time to live of records in the stream in milliseconds.
    retention_period_ms: int64 (id: 3);
}

// The create stream request is used to create a batch of streams.
// This frame with batch ability is very useful for importing metadata from other systems.
table CreateStreamRequest {
    // The timeout in milliseconds to wait for the response.
    timeout_ms: int32 (id: 0);

    // A batch of streams to create.
    stream: Stream (id: 1, required);
}

table CreateStreamResponse {
    // Flag status of the RPC.
    status: Status (id: 0, required);

    // The created stream
    stream: Stream (id: 1);

    // The time in milliseconds to throttle the client, due to a quota violation or the server is too busy.
    throttle_time_ms: int32 (id: 2);
}

// The delete streams request is used to delete a batch of streams to PM or data node.
// The PM will delete the stream metadata as well as the range info, while the data node only marks the stream as deleted to reject the new write requests timely.
table DeleteStreamRequest {

    // The timeout in milliseconds to wait for the response.
    timeout_ms: int32 (id: 0);

    // The id of the stream to delete.
    stream_id: int64 = -1 (id: 1);
}

table DeleteStreamResponse {
    status: Status (id: 0, required);

    // The deleted stream, or omitted if the stream is not deleted.
    stream: Stream (id: 1);

    // The time in milliseconds to throttle the client, due to a quota violation or the server is too busy.
    throttle_time_ms: int32 (id: 2);
}

table UpdateStreamRequest {
    // The timeout in milliseconds to wait for the response.
    timeout_ms: int32 (id: 0);

    // The streams to update.
    stream: Stream (id: 1);
}

table UpdateStreamResponse {
    status: Status (id: 0, required);

    // The time in milliseconds to throttle the client, due to a quota violation or the server is too busy.
    throttle_time_ms: int32 (id: 1);
    
    // The updated stream
    stream: Stream (id: 2);
}

table DescribeStreamRequest {
    // The timeout in milliseconds to wait for the response.
    timeout_ms: int32 (id: 0);

    // The ids of the streams to describe.
    stream_id: int64 (id: 1);
}

table DescribeStreamResponse {
    status: Status (id: 0, required);

    // The time in milliseconds to throttle the client, due to a quota violation or the server is too busy.
    throttle_time_ms: int32 (id: 1);

    // The stream, returned by the describe streams request.
    stream: Stream (id: 2);
}

// The trim streams request is used to trim a batch of streams to PM.
// The data node stores the records in the stream in a log structure,
// and the records are appended to the end of the log.
// Consider the length of disk is limited, the data node will delete the records to recycling the disk space.
// Once the deletion occurs, some ranges should be trimmed to avoid the clients to read the deleted records.

// The data node will send the TRIM_STREAMS frame to the PM to trim the stream with a trim offset.
// The PM will delete the ranges whose end offset is less than the trim offset
// and shrink the ranges whose start offset is less than the trim offset.
table TrimStreamRequest {
    // The timeout in milliseconds to wait for the response.
    timeout_ms: int32 (id: 0);

    // The id of the stream
    stream_id: int64 = -1 (id: 1);

    // The current minimum offset of the stream.
    // All the records before this offset have be deleted.
    min_offset: int64 (id: 2);
}

table TrimStreamsResponse {
    status: Status (id: 0, required);

    // The time in milliseconds to throttle the client, due to a quota violation or the server is too busy.
    throttle_time_ms: int32 (id: 1);
    
    // The trimmed stream
    stream: Stream (id: 2);

    // The smallest range of the stream after a trim operation.
    range: Range (id: 3);
}


table ReportMetricsRequest {
    data_node: DataNode (id: 0);

    metrics: DataNodeMetrics (id: 1);
}

table DataNodeMetrics {
    disk_in_rate: int64 (id: 0);
    disk_out_rate: int64 (id: 1);
    disk_free_space: int64 (id: 2);
    disk_unindexed_data_size: int64 (id: 3);
    memory_used: int64 (id: 4);
    uring_task_rate: int16 (id: 5);
    uring_inflight_task_cnt: int16 (id: 6);
    uring_pending_task_cnt: int32 (id: 7);
    uring_task_avg_latency: int16 (id: 8);
    network_append_rate: int16 (id: 9);
    network_fetch_rate: int16 (id: 10);
    network_failed_append_rate: int16 (id: 11);
    network_failed_fetch_rate: int16 (id: 12);
    network_append_avg_latency: int16 (id: 13);
    network_fetch_avg_latency: int16 (id: 14);
    range_missing_replica_cnt: int16 (id: 15);
    range_active_cnt: int16 (id: 16);
}

table ReportMetricsResponse {
    data_node: DataNode (id: 0);

    status: Status (id: 1, required);
}

table DescribePlacementManagerClusterRequest {
    // Data node that needs to know PM membership
    data_node: DataNode (id: 0, required);

    // The timeout in milliseconds to wait for the response.
    timeout_ms: int32 (id: 1);
}

table DescribePlacementManagerClusterResponse {
    status: Status (id: 0, required);
    
    cluster: PlacementManagerCluster (id: 1, required);
}
